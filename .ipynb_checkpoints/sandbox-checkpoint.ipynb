{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5995, 0.6548, 0.4221],\n",
      "        [0.0413, 0.1110, 0.2404],\n",
      "        [0.9150, 0.5478, 0.3657],\n",
      "        [0.4036, 0.7333, 0.0138],\n",
      "        [0.5564, 0.0238, 0.6337]])\n"
     ]
    }
   ],
   "source": [
    "# First, let's make sure that PyTorch is installed correctly.\n",
    "# This example is from https://pytorch.org/get-started/locally/\n",
    "# It should print out a tensor.\n",
    "\n",
    "from __future__ import print_function\n",
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforms.\n",
    "# Following this article:\n",
    "# https://towardsdatascience.com/transfer-learning-with-convolutional-neural-networks-in-pytorch-dd09190245ce\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "# Image transformations\n",
    "image_transforms = {\n",
    "    # Train uses data augmentation\n",
    "    'train':\n",
    "    transforms.Compose([\n",
    "        transforms.RandomResizedCrop(size=256, scale=(0.8, 1.0)),\n",
    "        transforms.RandomRotation(degrees=15),\n",
    "        transforms.ColorJitter(),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.CenterCrop(size=224),  # Image net standards\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])  # Imagenet standards\n",
    "    ]),\n",
    "    # Validation does not use augmentation\n",
    "    'valid':\n",
    "    transforms.Compose([\n",
    "        transforms.Resize(size=256),\n",
    "        transforms.CenterCrop(size=224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': <torch.utils.data.dataloader.DataLoader object at 0x7fe48e3643c8>, 'val': <torch.utils.data.dataloader.DataLoader object at 0x7fe48e364908>}\n"
     ]
    }
   ],
   "source": [
    "# Loading test data.\n",
    "\n",
    "from torchvision import datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "traindir = 'datadir/train/'\n",
    "validdir = 'datadir/valid/'\n",
    "testdir = 'datadir/test/'\n",
    "\n",
    "# Change to fit hardware\n",
    "batch_size = 128\n",
    "\n",
    "# Datasets from folders\n",
    "data = {\n",
    "    'train':\n",
    "    datasets.ImageFolder(root=traindir, transform=image_transforms['train']),\n",
    "    'valid':\n",
    "    datasets.ImageFolder(root=validdir, transform=image_transforms['valid']),\n",
    "}\n",
    "\n",
    "# Dataloader iterators, make sure to shuffle\n",
    "dataloaders = {\n",
    "    'train': DataLoader(data['train'], batch_size=batch_size, shuffle=True),\n",
    "    'val': DataLoader(data['valid'], batch_size=batch_size, shuffle=True)\n",
    "}\n",
    "\n",
    "print(dataloaders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 different classes.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Image manipulations\n",
    "from PIL import Image\n",
    "\n",
    "# Empty lists\n",
    "categories = []\n",
    "img_categories = []\n",
    "n_train = []\n",
    "n_valid = []\n",
    "n_test = []\n",
    "hs = []\n",
    "ws = []\n",
    "\n",
    "# Iterate through each category\n",
    "for d in os.listdir(traindir):\n",
    "    categories.append(d)\n",
    "\n",
    "    # Number of each image\n",
    "    train_imgs = os.listdir(traindir + d)\n",
    "    valid_imgs = os.listdir(validdir + d)\n",
    "    test_imgs = os.listdir(testdir + d)\n",
    "    n_train.append(len(train_imgs))\n",
    "    n_valid.append(len(valid_imgs))\n",
    "    n_test.append(len(test_imgs))\n",
    "\n",
    "    # Find stats for train images\n",
    "    for i in train_imgs:\n",
    "        img_categories.append(d)\n",
    "        img = Image.open(traindir + d + '/' + i)\n",
    "        img_array = np.array(img)\n",
    "        # Shape\n",
    "        hs.append(img_array.shape[0])\n",
    "        ws.append(img_array.shape[1])\n",
    "\n",
    "# Dataframe of categories\n",
    "cat_df = pd.DataFrame({'category': categories,\n",
    "                       'n_train': n_train,\n",
    "                       'n_valid': n_valid, 'n_test': n_test}).\\\n",
    "    sort_values('category')\n",
    "\n",
    "# Dataframe of training images\n",
    "image_df = pd.DataFrame({\n",
    "    'category': img_categories,\n",
    "    'height': hs,\n",
    "    'width': ws\n",
    "})\n",
    "\n",
    "cat_df.sort_values('n_train', ascending=False, inplace=True)\n",
    "cat_df.head()\n",
    "cat_df.tail()\n",
    "n_classes = len(cat_df)\n",
    "print(f'There are {n_classes} different classes.')\n",
    "\n",
    "len(data['train'].classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([128, 3, 224, 224]), torch.Size([128]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate through the dataloader once\n",
    "trainiter = iter(dataloaders['train'])\n",
    "features, labels = next(trainiter)\n",
    "features.shape, labels.shape\n",
    "\n",
    "# The shape of a batch is (batch_size, color_channels, height, width)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be False because of the way I installed it.\n",
    "\n",
    "from torch import optim, cuda\n",
    "cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace)\n",
      "    (2): Dropout(p=0.5)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace)\n",
      "    (5): Dropout(p=0.5)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# PyTorch has a number of models that have already been trained on millions of images from 1000 classes in Imagenet.\n",
    "# https://pytorch.org/docs/stable/torchvision/models.html\n",
    "\n",
    "from torchvision import models\n",
    "model = models.vgg16(pretrained=True)\n",
    "print(model)\n",
    "\n",
    "# Freeze model weights\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "# Transfer learning.\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "n_inputs = model.classifier[6].in_features\n",
    "\n",
    "# Add on classifier.\n",
    "# For the VGG-16, weâ€™re only changing the very last original fully-connected layer.\n",
    "# All of the weights in the convolutional layers and the the first 5 fully-connected layers are not trainable.\n",
    "model.classifier[6] = nn.Sequential(\n",
    "                      nn.Linear(n_inputs, 256), \n",
    "                      nn.ReLU(), \n",
    "                      nn.Dropout(0.4),\n",
    "                      nn.Linear(256, n_classes),                   \n",
    "                      nn.LogSoftmax(dim=1))\n",
    "\n",
    "# Only training classifier[6]\n",
    "model.classifier"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
